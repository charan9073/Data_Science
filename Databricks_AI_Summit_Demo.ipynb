{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "684ca640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"scale_settings\": {\n",
      "        \"scale_type\": \"standard\"\n",
      "      },\n",
      "      \"model\": \"text-search-curie-doc-001\",\n",
      "      \"owner\": \"organization-owner\",\n",
      "      \"id\": \"text-search-curie-doc-001\",\n",
      "      \"status\": \"succeeded\",\n",
      "      \"created_at\": 1683713968,\n",
      "      \"updated_at\": 1683713968,\n",
      "      \"object\": \"deployment\"\n",
      "    },\n",
      "    {\n",
      "      \"scale_settings\": {\n",
      "        \"scale_type\": \"standard\"\n",
      "      },\n",
      "      \"model\": \"text-embedding-ada-002\",\n",
      "      \"owner\": \"organization-owner\",\n",
      "      \"id\": \"text-embedding-ada-002\",\n",
      "      \"status\": \"succeeded\",\n",
      "      \"created_at\": 1683713993,\n",
      "      \"updated_at\": 1683713993,\n",
      "      \"object\": \"deployment\"\n",
      "    },\n",
      "    {\n",
      "      \"scale_settings\": {\n",
      "        \"scale_type\": \"standard\"\n",
      "      },\n",
      "      \"model\": \"text-search-curie-query-001\",\n",
      "      \"owner\": \"organization-owner\",\n",
      "      \"id\": \"text-search-curie-query-001\",\n",
      "      \"status\": \"succeeded\",\n",
      "      \"created_at\": 1683714930,\n",
      "      \"updated_at\": 1683714930,\n",
      "      \"object\": \"deployment\"\n",
      "    },\n",
      "    {\n",
      "      \"scale_settings\": {\n",
      "        \"scale_type\": \"standard\"\n",
      "      },\n",
      "      \"model\": \"text-davinci-003\",\n",
      "      \"owner\": \"organization-owner\",\n",
      "      \"id\": \"text-davinci-003\",\n",
      "      \"status\": \"succeeded\",\n",
      "      \"created_at\": 1683715478,\n",
      "      \"updated_at\": 1683715478,\n",
      "      \"object\": \"deployment\"\n",
      "    },\n",
      "    {\n",
      "      \"scale_settings\": {\n",
      "        \"scale_type\": \"standard\"\n",
      "      },\n",
      "      \"model\": \"gpt-35-turbo\",\n",
      "      \"owner\": \"organization-owner\",\n",
      "      \"id\": \"gpt-35-turbo\",\n",
      "      \"status\": \"succeeded\",\n",
      "      \"created_at\": 1684499438,\n",
      "      \"updated_at\": 1684499438,\n",
      "      \"object\": \"deployment\"\n",
      "    }\n",
      "  ],\n",
      "  \"object\": \"list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "from num2words import num2words\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "API_KEY = \"18bc8a0873114be0be0d32d6e05122d4\"\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = API_KEY\n",
    "openai.api_base = \"https://coe-azopenai-scus.openai.azure.com/\" \n",
    "openai.api_version = \"2022-12-01\"\n",
    "\n",
    "url = openai.api_base + \"/openai/deployments?api-version=2022-12-01\"\n",
    "\n",
    "r = requests.get(url, headers={\"api-key\": API_KEY})\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "730d58e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "    table.dataframe td, table.dataframe th {\n",
       "        border-style: solid;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    "    table.dataframe td, table.dataframe th {\n",
    "        border-style: solid;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa595385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Databricks_api_with_embedings.csv',encoding = 'utf8',usecols=['API','Description','Parameters','token_count','curie_search'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "defa0c0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API</th>\n",
       "      <th>Description</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>token_count</th>\n",
       "      <th>curie_search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>list_clusters()</td>\n",
       "      <td>Return information about all pinned clusters, ...</td>\n",
       "      <td>NOPARAM</td>\n",
       "      <td>127</td>\n",
       "      <td>[-0.003413616679608822, 0.00466638058423996, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>create_cluster()</td>\n",
       "      <td>Creates a new Spark cluster. This method will ...</td>\n",
       "      <td>cluster_name,spark_version,node_type_id,num_wo...</td>\n",
       "      <td>63</td>\n",
       "      <td>[-0.007258645258843899, -0.014390581287443638,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>start_cluster()</td>\n",
       "      <td>Starts a terminated Spark cluster with the sup...</td>\n",
       "      <td>cluster_id</td>\n",
       "      <td>69</td>\n",
       "      <td>[-0.005574929062277079, 0.0060096918605268, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>restart_cluster()</td>\n",
       "      <td>Restarts a Spark cluster with the supplied CLU...</td>\n",
       "      <td>cluster_id</td>\n",
       "      <td>26</td>\n",
       "      <td>[-0.0059488434344530106, 0.0009289347799494863...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resize_cluster()</td>\n",
       "      <td>Resizes a cluster to have a desired number of ...</td>\n",
       "      <td>cluster_id,num_workers</td>\n",
       "      <td>134</td>\n",
       "      <td>[-0.016329452395439148, -0.008979315869510174,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>terminate_cluster()</td>\n",
       "      <td>To save cluster resources, you can terminate a...</td>\n",
       "      <td>cluster_id</td>\n",
       "      <td>180</td>\n",
       "      <td>[-0.02185562066733837, -0.0054865204729139805,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>delete_cluster()</td>\n",
       "      <td>Deleting a cluster terminates the cluster and ...</td>\n",
       "      <td>cluster_id</td>\n",
       "      <td>57</td>\n",
       "      <td>[-0.007029342465102673, -0.011882157064974308,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>list_cluster_policies()</td>\n",
       "      <td>Returns a list of policies accessible by the r...</td>\n",
       "      <td>NOPARAM</td>\n",
       "      <td>11</td>\n",
       "      <td>[-0.0017335671000182629, -0.005269116256386042...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>get_cluster_policy()</td>\n",
       "      <td>Get a cluster policy entity. Creation and edit...</td>\n",
       "      <td>policy_id</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.0006803972646594048, -0.01730068400502205, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>create_cluster_policy()</td>\n",
       "      <td>Cluster Policy name requested by the user. Thi...</td>\n",
       "      <td>name,definition</td>\n",
       "      <td>25</td>\n",
       "      <td>[-0.005265526007860899, -0.017011698335409164,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>edit_cluster_policy()</td>\n",
       "      <td>Update an existing policy for cluster. This op...</td>\n",
       "      <td>policy_id</td>\n",
       "      <td>20</td>\n",
       "      <td>[0.0009108876110985875, -0.008996128104627132,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>delete_cluster_policy()</td>\n",
       "      <td>Delete a policy for a cluster. Clusters govern...</td>\n",
       "      <td>policy_id</td>\n",
       "      <td>22</td>\n",
       "      <td>[-0.004755288362503052, -0.013668179512023926,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>list_files()</td>\n",
       "      <td>List the contents of a directory, or details o...</td>\n",
       "      <td>Path</td>\n",
       "      <td>122</td>\n",
       "      <td>[-0.0011738904286175966, 0.01097327284514904, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>file_exists()</td>\n",
       "      <td>Get the file information of a file or director...</td>\n",
       "      <td>Path</td>\n",
       "      <td>30</td>\n",
       "      <td>[0.014726397581398487, 0.01172140333801508, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>get_status()</td>\n",
       "      <td>Gets the file information for a file or direct...</td>\n",
       "      <td>Path</td>\n",
       "      <td>31</td>\n",
       "      <td>[0.012925412505865097, 0.0065710460767149925, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>put_file()</td>\n",
       "      <td>Upload a file through the use of multipart for...</td>\n",
       "      <td>Path</td>\n",
       "      <td>73</td>\n",
       "      <td>[-0.0011715760920196772, 0.005459231324493885,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mkdirs()</td>\n",
       "      <td>Create the given directory and necessary paren...</td>\n",
       "      <td>Path</td>\n",
       "      <td>74</td>\n",
       "      <td>[0.013322086073458195, 0.006172847934067249, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>move()</td>\n",
       "      <td>Move a file from one location to another locat...</td>\n",
       "      <td>source_path,destination_path</td>\n",
       "      <td>71</td>\n",
       "      <td>[0.0032780873589217663, 0.0099133076146245, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>copy()</td>\n",
       "      <td>Copy files from one directory location to anot...</td>\n",
       "      <td>source_path,destination_path</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.01823374815285206, 0.0023441368248313665, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        API  \\\n",
       "0           list_clusters()   \n",
       "1          create_cluster()   \n",
       "2           start_cluster()   \n",
       "3         restart_cluster()   \n",
       "4          resize_cluster()   \n",
       "5       terminate_cluster()   \n",
       "6          delete_cluster()   \n",
       "7   list_cluster_policies()   \n",
       "8      get_cluster_policy()   \n",
       "9   create_cluster_policy()   \n",
       "10    edit_cluster_policy()   \n",
       "11  delete_cluster_policy()   \n",
       "12             list_files()   \n",
       "13            file_exists()   \n",
       "14             get_status()   \n",
       "15               put_file()   \n",
       "16                 mkdirs()   \n",
       "17                   move()   \n",
       "18                   copy()   \n",
       "\n",
       "                                          Description  \\\n",
       "0   Return information about all pinned clusters, ...   \n",
       "1   Creates a new Spark cluster. This method will ...   \n",
       "2   Starts a terminated Spark cluster with the sup...   \n",
       "3   Restarts a Spark cluster with the supplied CLU...   \n",
       "4   Resizes a cluster to have a desired number of ...   \n",
       "5   To save cluster resources, you can terminate a...   \n",
       "6   Deleting a cluster terminates the cluster and ...   \n",
       "7   Returns a list of policies accessible by the r...   \n",
       "8   Get a cluster policy entity. Creation and edit...   \n",
       "9   Cluster Policy name requested by the user. Thi...   \n",
       "10  Update an existing policy for cluster. This op...   \n",
       "11  Delete a policy for a cluster. Clusters govern...   \n",
       "12  List the contents of a directory, or details o...   \n",
       "13  Get the file information of a file or director...   \n",
       "14  Gets the file information for a file or direct...   \n",
       "15  Upload a file through the use of multipart for...   \n",
       "16  Create the given directory and necessary paren...   \n",
       "17  Move a file from one location to another locat...   \n",
       "18  Copy files from one directory location to anot...   \n",
       "\n",
       "                                           Parameters  token_count  \\\n",
       "0                                             NOPARAM          127   \n",
       "1   cluster_name,spark_version,node_type_id,num_wo...           63   \n",
       "2                                          cluster_id           69   \n",
       "3                                          cluster_id           26   \n",
       "4                             cluster_id,num_workers           134   \n",
       "5                                          cluster_id          180   \n",
       "6                                          cluster_id           57   \n",
       "7                                             NOPARAM           11   \n",
       "8                                           policy_id           15   \n",
       "9                                     name,definition           25   \n",
       "10                                          policy_id           20   \n",
       "11                                          policy_id           22   \n",
       "12                                               Path          122   \n",
       "13                                               Path           30   \n",
       "14                                               Path           31   \n",
       "15                                               Path           73   \n",
       "16                                               Path           74   \n",
       "17                       source_path,destination_path           71   \n",
       "18                       source_path,destination_path           17   \n",
       "\n",
       "                                         curie_search  \n",
       "0   [-0.003413616679608822, 0.00466638058423996, 0...  \n",
       "1   [-0.007258645258843899, -0.014390581287443638,...  \n",
       "2   [-0.005574929062277079, 0.0060096918605268, 0....  \n",
       "3   [-0.0059488434344530106, 0.0009289347799494863...  \n",
       "4   [-0.016329452395439148, -0.008979315869510174,...  \n",
       "5   [-0.02185562066733837, -0.0054865204729139805,...  \n",
       "6   [-0.007029342465102673, -0.011882157064974308,...  \n",
       "7   [-0.0017335671000182629, -0.005269116256386042...  \n",
       "8   [0.0006803972646594048, -0.01730068400502205, ...  \n",
       "9   [-0.005265526007860899, -0.017011698335409164,...  \n",
       "10  [0.0009108876110985875, -0.008996128104627132,...  \n",
       "11  [-0.004755288362503052, -0.013668179512023926,...  \n",
       "12  [-0.0011738904286175966, 0.01097327284514904, ...  \n",
       "13  [0.014726397581398487, 0.01172140333801508, -0...  \n",
       "14  [0.012925412505865097, 0.0065710460767149925, ...  \n",
       "15  [-0.0011715760920196772, 0.005459231324493885,...  \n",
       "16  [0.013322086073458195, 0.006172847934067249, 0...  \n",
       "17  [0.0032780873589217663, 0.0099133076146245, 0....  \n",
       "18  [0.01823374815285206, 0.0023441368248313665, 0...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a598f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"curie_search\"] = df.curie_search.apply(eval).apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "068eeb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s is input text\n",
    "def normalize_text(s, sep_token = \" \\n \"):\n",
    "    s = re.sub(r'\\s+',  ' ', s).strip()\n",
    "    s = re.sub(r\". ,\",\"\",s)\n",
    "    # remove all instances of multiple spaces\n",
    "    s = s.replace(\"..\",\".\")\n",
    "    s = s.replace(\". .\",\".\")\n",
    "    s = s.replace(\"\\n\", \"\")\n",
    "    s = s.strip()\n",
    "    \n",
    "    return s\n",
    "\n",
    "df['text'] = df[\"Description\"].apply(lambda x : normalize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3adacd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search through the reviews for a specific product\n",
    "def search_docs(df, user_query, top_n=3, to_print=False):\n",
    "    embedding = get_embedding(\n",
    "        user_query,\n",
    "        engine=\"text-search-curie-query-001\"\n",
    "    )\n",
    "    df[\"similarities\"] = df.curie_search.apply(lambda x: cosine_similarity(x, embedding))\n",
    "\n",
    "    res = (\n",
    "        df.sort_values(\"similarities\", ascending=False)\n",
    "        .head(top_n)\n",
    "    )\n",
    "    if to_print:\n",
    "        display(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "res = search_docs(df, \"what are clusters are there?\", top_n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69197928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cip(query,p):\n",
    "    prompt=f\"\"\"Identify the parameters ({p}) \\\n",
    "from the following context. Format your answer as a single value corresponding to the parameter and set as NA if the value is not found within the context.: \\n\n",
    "Context: \\n{query}\\n\n",
    "Parameters:\\n({p})=(\n",
    "\"\"\"\n",
    "    #print(prompt)\n",
    "\n",
    "    out = openai.Completion.create(\n",
    "    engine='text-davinci-003',\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=100,\n",
    "    suffix=\")\")\n",
    "    s=out['choices'][0]['text']\n",
    "    return True,s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a77f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query='Can you please give me list of clusters '\n",
    "res = search_docs(df, query, top_n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f502339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_in_prompt(query, param):\n",
    "    params={}\n",
    "    if res.iloc[0]['Parameters']!='NOPARAM':\n",
    "        for p in res.iloc[0]['Parameters'].split(','):\n",
    "            status, param = cip(query,p)\n",
    "            if status == True:\n",
    "                params[p]=normalize_text(param)\n",
    "    return True,params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e38ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "status, params = check_in_prompt(query, res.iloc[0]['Parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f2df2803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from databricks_cli.sdk.api_client import ApiClient\n",
    "from databricks_api import DatabricksAPI\n",
    "from databricks_cli.clusters.api import ClusterApi\n",
    "from databricks_cli.cluster_policies.api import ClusterPolicyApi\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_client = ApiClient(\n",
    "    host=\"https://lti-datascience-coe.cloud.databricks.com\",\n",
    "    token=\"dapi36506604639e5b76af065969be4fdcc9\"\n",
    "    )\n",
    "\n",
    "db = DatabricksAPI(\n",
    "    host=\"https://lti-datascience-coe.cloud.databricks.com\",\n",
    "    token=\"dapi36506604639e5b76af065969be4fdcc9\"\n",
    ")\n",
    "\n",
    "clusters_api = ClusterApi(api_client)\n",
    "cluster_policies_api = ClusterPolicyApi(api_client)\n",
    "\n",
    "def clusters_list(param):\n",
    "    ls = []\n",
    "    for cl in clusters_api.list_clusters()['clusters']:\n",
    "        cl_id = cl['cluster_id']\n",
    "        cl_name = cl['cluster_name']\n",
    "        cl_state = cl['state']\n",
    "        ls.append([cl_id,cl_name,cl_state])\n",
    "        \n",
    "    return pd.DataFrame(ls,columns=['cluster_id','cl_name','cl_state']) # list clusters\n",
    "\n",
    "def terminate_clusters(cluster_id):\n",
    "    clusters_api.delete_cluster(cluster_id)\n",
    "    \n",
    "def delete_clusters(cluster_id):\n",
    "    clusters_api.permanent_delete(cluster_id)\n",
    "    \n",
    "def start_clusters(cluster_id):\n",
    "    clusters_api.start_cluster(cluster_id)\n",
    "    \n",
    "def restart_clusters(cluster_id):\n",
    "    clusters_api.restart_cluster(cluster_id)\n",
    "\n",
    "def create_cluster(cluster_name, spark_version, node_type_id,num_workers):\n",
    "    try:\n",
    "        cluster = db.cluster.create_cluster(\n",
    "            cluster_name=cluster_name,\n",
    "            spark_version=spark_version,\n",
    "            node_type_id=node_type_id,\n",
    "            num_workers=num_workers\n",
    "        )\n",
    "        return cluster\n",
    "    except Exception as e:\n",
    "        print('Error creating Databricks cluster:', str(e))\n",
    "        return None\n",
    "    \n",
    "def resize_cluster(cluster_id,num_workers):\n",
    "    db.cluster.resize_cluster(\n",
    "             cluster_id = cluster_id ,\n",
    "             num_workers= num_workers)   \n",
    "\n",
    "#### Cluster Policy\n",
    "    \n",
    "def cluster_policy_list(param):\n",
    "    ls = []\n",
    "    for pl in cluster_policies_api.list_cluster_policies()['policies']:\n",
    "        pl_id = pl['policy_id']\n",
    "        pl_name = pl['name']\n",
    "        ls.append([pl_id,pl_name])\n",
    "    return pd.DataFrame(ls, columns=['policy_id','name'])\n",
    "    \n",
    "def get_cluster_policy(policy_id):\n",
    "    cluster_policies_api.get_policy(policy_id)\n",
    "\n",
    "def create_cluster_policy(policy_name, config_file_path):\n",
    "    api_endpoint = \"https://lti-datascience-coe.cloud.databricks.com/api/2.0/policies/clusters/create\"  # Replace <databricks-instance> with your Databricks instance URL\n",
    "    api_token = \"dapi36506604639e5b76af065969be4fdcc9\"\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer \" + api_token,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    with open(config_file_path, 'r') as file:\n",
    "        config_data = json.load(file)\n",
    "\n",
    "    config_data[\"name\"] = policy_name\n",
    "\n",
    "    response = requests.post(api_endpoint, headers=headers, json=config_data)\n",
    "    response_json = response.json()\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(\"Cluster policy created successfully with ID:\", response_json[\"policy_id\"])\n",
    "    else:\n",
    "        print(\"Error creating cluster policy:\", response_json[\"message\"])\n",
    "\n",
    "def delete_clusters_ploicy(policy_id):\n",
    "    return cluster_policies_api.delete_cluster_policy(policy_id)\n",
    "\n",
    "#########\n",
    "# DBFS\n",
    "#######\n",
    "def list_files(path):\n",
    "    db.dbfs.list(path=path)\n",
    "    \n",
    "def make_dirs(path):\n",
    "    db.dbfs.mkdirs(path=path)\n",
    "    \n",
    "def move_file(source_path,destination_path):\n",
    "    db.dbfs.move(source_path = source_path,\n",
    "                 destination_path = destination_path\n",
    "                 )\n",
    "def get_status(path):\n",
    "    db.dbfs.get_status(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66bf26f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_databricks_cluster(dictionary):\n",
    "    print('Dict:',dictionary)\n",
    "    status = True\n",
    "    running=True\n",
    "    while running:\n",
    "        if 'cluster_id' not in dictionary:\n",
    "            print(\"There is no cluster_id present in the query, so please enter the cluster_id from the below list\")\n",
    "            print(clusters_list(''))\n",
    "            inp=input(\"Please enter the correct cluster id or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "            elif inp in clusters_list('')['cluster_id']:\n",
    "                start_clusters(cluster_id)\n",
    "                print(\"Successfully Started the clusters:\",inp)\n",
    "                running=False\n",
    "            else:\n",
    "                dictionary['cluster_id']=inp\n",
    "        elif 'cluster_id' in dictionary and dictionary['cluster_id'] in [str(cid) for cid in clusters_list('')['cluster_id']]:\n",
    "            start_clusters(dictionary['cluster_id'])\n",
    "            print(\"Successfully Started the clusters:\",dictionary['cluster_id'])\n",
    "            running=False\n",
    "        else:\n",
    "            print(\"The clusterid provided does not exist so please enter the cluster_id from below list or enter 'quit'\")\n",
    "            print(clusters_list(''))\n",
    "            inp=input(\"Please enter the correct cluster id or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "            elif inp in clusters_list('')['cluster_id']:\n",
    "                start_clusters(cluster_id)\n",
    "                print(\"Successfully Started the clusters:\",inp)\n",
    "                running=False\n",
    "            else:\n",
    "                dictionary['cluster_id']=inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddce48ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restart_databricks_cluster(dictionary):\n",
    "    print('Dict:',dictionary)\n",
    "    status = True\n",
    "    running=True\n",
    "    while running:\n",
    "        if 'cluster_id' not in dictionary:\n",
    "            print(\"There is no cluster_id present in the query, so please enter the cluster_id from the below list\")\n",
    "            print(clusters_list(''))\n",
    "            inp=input(\"Please enter the correct cluster id or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "            elif inp in clusters_list('')['cluster_id']:\n",
    "                restart_clusters(cluster_id)\n",
    "                print(\"Successfully Restarted the clusters:\",inp)\n",
    "                running=False\n",
    "            else:\n",
    "                dictionary['cluster_id']=inp\n",
    "        elif 'cluster_id' in dictionary and dictionary['cluster_id'] in [str(cid) for cid in clusters_list('')['cluster_id']]:\n",
    "            restart_clusters(dictionary['cluster_id'])\n",
    "            print(\"Successfully Restarted the clusters:\",dictionary['cluster_id'])\n",
    "            running=False\n",
    "        else:\n",
    "            print(\"The clusterid provided does not exist so please enter the cluster_id from below list or enter 'quit'\")\n",
    "            print(clusters_list(''))\n",
    "            inp=input(\"Please enter the correct cluster id or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "            elif inp in clusters_list('')['cluster_id']:\n",
    "                restart_clusters(cluster_id)\n",
    "                print(\"Successfully Restarted the clusters:\",inp)\n",
    "                running=False\n",
    "            else:\n",
    "                dictionary['cluster_id']=inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f864f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminate_cluster_from_cluster_list(dictionary):\n",
    "    print('Dict:',dictionary)\n",
    "    status = True\n",
    "    running=True\n",
    "    while running:\n",
    "        if 'cluster_id' not in dictionary:\n",
    "            print(\"There is no cluster_id present in the query, so please enter the cluster_id from the below list\")\n",
    "            print(clusters_list(''))\n",
    "            inp=input(\"Please enter the correct cluster id or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "            elif inp in clusters_list('')['cluster_id']:\n",
    "                terminate_clusters(cluster_id)\n",
    "                print(\"Successfully Terminated the clusters:\",inp)\n",
    "                running=False\n",
    "            else:\n",
    "                dictionary['cluster_id']=inp\n",
    "        elif 'cluster_id' in dictionary and dictionary['cluster_id'] in [str(cid) for cid in clusters_list('')['cluster_id']]:\n",
    "            terminate_clusters(dictionary['cluster_id'])\n",
    "            print(\"Successfully Terminated the clusters:\",dictionary['cluster_id'])\n",
    "            running=False\n",
    "        else:\n",
    "            print(\"The clusterid provided does not exist so please enter the cluster_id from below list or enter 'quit'\")\n",
    "            print(clusters_list(''))\n",
    "            inp=input(\"Please enter the correct cluster id or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "            elif inp in clusters_list('')['cluster_id']:\n",
    "                terminate_clusters(cluster_id)\n",
    "                print(\"Successfully Terminated the clusters:\",inp)\n",
    "                running=False\n",
    "            else:\n",
    "                dictionary['cluster_id']=inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23d29e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permanent_delete_cluster_from_list(dictionary):\n",
    "    print('Dict:',dictionary)\n",
    "    status = True\n",
    "    running=True\n",
    "    while running:\n",
    "        if 'cluster_id' not in dictionary:\n",
    "            print(\"There is no cluster_id present in the query, so please enter the cluster_id from the below list\")\n",
    "            print(clusters_list(''))\n",
    "            inp=input(\"Please enter the correct cluster id or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "            elif inp in clusters_list('')['cluster_id']:\n",
    "                delete_clusters(cluster_id)\n",
    "                print(\"Successfully Deleted Permanently the clusters:\",inp)\n",
    "                running=False\n",
    "            else:\n",
    "                dictionary['cluster_id']=inp\n",
    "        elif 'cluster_id' in dictionary and dictionary['cluster_id'] in [str(cid) for cid in clusters_list('')['cluster_id']]:\n",
    "            delete_clusters(dictionary['cluster_id'])\n",
    "            print(\"Successfully Deleted Permanently the clusters:\",dictionary['cluster_id'])\n",
    "            running=False\n",
    "        else:\n",
    "            print(\"The clusterid provided does not exist so please enter the cluster_id from below list or enter 'quit'\")\n",
    "            print(clusters_list(''))\n",
    "            inp=input(\"Please enter the correct cluster id or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "            elif inp in clusters_list('')['cluster_id']:\n",
    "                delete_clusters(cluster_id)\n",
    "                print(\"Successfully Deleted Permanently the clusters:\",inp)\n",
    "                running=False\n",
    "            else:\n",
    "                dictionary['cluster_id']=inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42808ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_policy_from_policy_list(dictionary):\n",
    "    print('Dict:',dictionary)\n",
    "    status = True\n",
    "    running=True\n",
    "    while running:\n",
    "        if 'policy_id' not in dictionary:\n",
    "            print(\"There is no policy_id present in the query, so please enter the policy_id from the below list\")\n",
    "            print(cluster_policy_list(''))\n",
    "            inp=input(\"Please enter the correct policy id or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "            elif inp in cluster_policy_list('')['policy_id']:\n",
    "                delete_clusters_ploicy(policy_id)\n",
    "                print(\"Successfully Deleted the policy:\",inp)\n",
    "                running=False\n",
    "            else:\n",
    "                dictionary['policy_id']=inp\n",
    "        elif 'policy_id' in dictionary and dictionary['policy_id'] in cluster_policy_list('')['policy_id']:\n",
    "            delete_clusters_ploicy(policy_id)\n",
    "            print(\"Successfully Deleted the policy:\",inp)\n",
    "            running=False\n",
    "        else:\n",
    "            print(\"The policyid provided does not exist so please enter the policy_id from below list or enter 'quit'\")\n",
    "            print(cluster_policy_list(''))\n",
    "            inp=input(\"Please enter the correct policy id or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "            elif inp in cluster_policy_list('')['cluster_id']:\n",
    "                delete_clusters_ploicy(policy_id)\n",
    "                print(\"Successfully Deleted the policy:\",inp)\n",
    "                running=False\n",
    "            else:\n",
    "                dictionary['policy_id']=inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "430e6e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_databricks_policy(dictionary):\n",
    "    print('Dict:',dictionary)\n",
    "    status = True\n",
    "    running=True\n",
    "    while running:\n",
    "        if 'policy_id' not in dictionary:\n",
    "            print(\"There is no policy_id present in the query, so please enter the policy_id from the below list\")\n",
    "            print(cluster_policy_list(''))\n",
    "            inp=input(\"Please enter the correct policy id or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "            elif inp in cluster_policy_list('')['policy_id']:\n",
    "                get_cluster_policy(policy_id)\n",
    "                print(\"Successfully Deleted the policy:\",inp)\n",
    "                running=False\n",
    "            else:\n",
    "                dictionary['policy_id']=inp\n",
    "        elif 'policy_id' in dictionary and dictionary['policy_id'] in cluster_policy_list('')['policy_id']:\n",
    "            get_cluster_policy(policy_id)\n",
    "            print(\"Successfully Deleted the policy:\",inp)\n",
    "            running=False\n",
    "        else:\n",
    "            print(\"The policyid provided does not exist so please enter the policy_id from below list or enter 'quit'\")\n",
    "            print(cluster_policy_list(''))\n",
    "            inp=input(\"Please enter the correct policy id or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "            elif inp in cluster_policy_list('')['cluster_id']:\n",
    "                get_cluster_policy(policy_id)\n",
    "                print(\"Successfully Deleted the policy:\",inp)\n",
    "                running=False\n",
    "            else:\n",
    "                dictionary['policy_id']=inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5875a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_databricks_clusters(dictionary):\n",
    "    print('Dict:',dictionary)\n",
    "    status = True\n",
    "    running=True\n",
    "    while running:\n",
    "        try:\n",
    "            print(\"Create cluster started.....\")\n",
    "            print(\"Please give these inputs to create cluster....\")\n",
    "            cluster_name = input(\"Enter the cluster name: \")\n",
    "            spark_version = input(\"Enter the Spark version: \")\n",
    "            node_type_id = input(\"Enter the node type ID: \")\n",
    "            num_workers = input(\"Enter the num_workers: \")\n",
    "            response= create_cluster(cluster_name, spark_version, node_type_id,num_workers)\n",
    "            print(\"Cluster Created Successfully....\",response[\"cluster_id\"])\n",
    "            inp=input(\"Cluster is created,Please enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False \n",
    "        except:\n",
    "            inp=input(\"Please enter the correct input or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "                print(\"Failed to Create the cluster please Check....\")\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a80cd0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_databricks_clusters(dictionary):\n",
    "    print('Dict:',dictionary)\n",
    "    status = True\n",
    "    running=True\n",
    "    while running:\n",
    "        try:\n",
    "            print(\"Resize cluster started.....\")\n",
    "            print(\"Please give these inputs to resize cluster....\")\n",
    "            cluster_id = input(\"Enter the cluster_id: \")\n",
    "            num_workers = input(\"Enter the num_workers: \")\n",
    "            resize_cluster(cluster_id,num_workers)\n",
    "            print(\"Cluster Resized Successfully....\")\n",
    "            inp=input(\"Cluster is Resized,Please enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False \n",
    "        except:\n",
    "            inp=input(\"Please enter the correct input or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "                print(\"Failed to resize the cluster please Check....\")\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c82437e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_databricks_cluster_policies(dictionary):\n",
    "    print('Dict:',dictionary)\n",
    "    status = True\n",
    "    running=True\n",
    "    while running:\n",
    "        try:\n",
    "            print(\"Create cluster policy started.....\")\n",
    "            print(\"Please give these inputs to create cluster policy....\")\n",
    "            policy_name = input(\"Enter the cluster name: \")\n",
    "            config_file_path = input(\"Enter the JSON config_file_path file: \")\n",
    "            create_cluster_policy(policy_name, config_file_path)\n",
    "            print(\"Cluster policy Created Successfully....\")\n",
    "            inp=input(\"Cluster policy is created,Please enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False \n",
    "        except:\n",
    "            inp=input(\"Please enter the correct input or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "                print(\"Failed to Create the cluster policy please Check....\")\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbe40e2",
   "metadata": {},
   "source": [
    "#### DBFS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d41b6e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_databricks_file(dictionary):\n",
    "    print('Dict:',dictionary)\n",
    "    status = True\n",
    "    running=True\n",
    "    while running:\n",
    "        try:\n",
    "            print(\"Listing files databricks started.....\")\n",
    "            print(\"Please give the path as input to list the files....\")\n",
    "            path = input(\"Enter the databricks path: \")\n",
    "            list_files(path)\n",
    "            print(\"listing the files in Databricks successful....\")\n",
    "            inp=input(\"file listing has successfull done,Please enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False \n",
    "        except:\n",
    "            inp=input(\"Please enter the correct input or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "                print(\"Failed to list the files in Databricks please Check....\")\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "be4764e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def databricks_file_status(dictionary):\n",
    "    print('Dict:',dictionary)\n",
    "    status = True\n",
    "    running=True\n",
    "    while running:\n",
    "        try:\n",
    "            print(\"databricks file status started.....\")\n",
    "            print(\"Please give the path as input to check the status....\")\n",
    "            path = input(\"Enter the databricks path: \")\n",
    "            get_status(path)\n",
    "            print(\"databricks file status successful....\")\n",
    "            inp=input(\"databricks file status check successfull done,Please enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False \n",
    "        except:\n",
    "            inp=input(\"Please enter the correct input or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "                print(\"Failed to check the Databricks file status please Check....\")\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2d7b8edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def databricks_create_directory(dictionary):\n",
    "    print('Dict:',dictionary)\n",
    "    status = True\n",
    "    running=True\n",
    "    while running:\n",
    "        try:\n",
    "            print(\"databricks directory creation started.....\")\n",
    "            print(\"Please give the path as input to check the status....\")\n",
    "            path = input(\"Enter the databricks path: \")\n",
    "            make_dirs(path)\n",
    "            print(\"databricks directory created successful....\")\n",
    "            inp=input(\"databricks directory creation successfully done,Please enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False \n",
    "        except:\n",
    "            inp=input(\"Please enter the correct input or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "                print(\"Failed to create Databricks directory ,please Check....\")\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "991ef3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_file(dictionary):\n",
    "    print('Dict:',dictionary)\n",
    "    status = True\n",
    "    running=True\n",
    "    while running:\n",
    "        try:\n",
    "            print(\"databricks file moving started.....\")\n",
    "            print(\"Please give the path as input to check the status....\")\n",
    "            source_path = input(\"Enter the source databricks path\")\n",
    "            destination_path = input(\"Enter the destination databricks path: \")\n",
    "            move_file(source_path,destination_path)\n",
    "            print(\"Moving file from source to destination in Databricks has done successfully....\")\n",
    "            inp=input(\"Moving file from source to destination in Databricks has done successfully,Please enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False \n",
    "        except:\n",
    "            inp=input(\"Please enter the correct input or enter'quit' to exit\\n\")\n",
    "            if inp=='quit':\n",
    "                running=False\n",
    "                print(\"Failed to move file from source to destination in Databricks ,please Check....\")\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d6eb4d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Databricks Codex.Enter your query\n",
      "Can you please create cluster policy?\n",
      "Please enter (y/n) is you want to execute below API:\n",
      "get_cluster_policy()\n",
      "n\n",
      "Cannot undertsand your input.Let's begin from the begining\n",
      "Welcome to Databricks Codex.Enter your query\n",
      "Cluster Policy name requested by the user?\n",
      "Please enter (y/n) is you want to execute below API:\n",
      "create_cluster_policy()\n",
      "y\n",
      "Dict: {'name': 'NA', 'definition': 'NA'}\n",
      "Create cluster policy started.....\n",
      "Please give these inputs to create cluster policy....\n",
      "Enter the cluster name: Test_policy_Charan\n",
      "Enter the JSON config_file_path file: config_file_path.json\n",
      "Cluster policy created successfully with ID: 9C63D8C50400CE3A\n",
      "Please enter the correct input or enter'quit' to exit\n",
      "quit\n",
      "Failed to Create the cluster policy please Check....\n",
      "None\n",
      "Successfully Executed the query. Do you wish to continue(y/n)?n\n"
     ]
    }
   ],
   "source": [
    "#One session i started the state is set to start\n",
    "func_dict={'list_clusters()':clusters_list,\n",
    "           'create_cluster()' : create_databricks_clusters,\n",
    "           'start_cluster()':start_databricks_cluster,\n",
    "           'restart_cluster()' :restart_databricks_cluster,\n",
    "           'resize_cluster()' :resize_databricks_clusters,\n",
    "           'terminate_cluster()':terminate_cluster_from_cluster_list,\n",
    "           'delete_cluster()':permanent_delete_cluster_from_list,\n",
    "           'list_cluster_policies()':cluster_policy_list,\n",
    "           'get_cluster_policy()': get_databricks_policy,\n",
    "           'create_cluster_policy()': create_databricks_cluster_policies,\n",
    "           'delete_cluster_policy()':delete_policy_from_policy_list,\n",
    "           'list_files()' : list_databricks_file,\n",
    "           'get_status()' : databricks_file_status,\n",
    "           'mkdirs()' : databricks_create_directory,\n",
    "           'move()' : databricks_file_move}\n",
    "state='start'\n",
    "while state != 'stop':\n",
    "    query=input(\"Welcome to Databricks Codex.Enter your query\\n\")\n",
    "    if query !='':\n",
    "        res=search_docs(df, query, top_n=4)\n",
    "        api=res.iloc[0]['API']\n",
    "        _,param = check_in_prompt(query,res.iloc[0]['Parameters'])\n",
    "        inp = input(f\"Please enter (y/n) is you want to execute below API:\\n{api}\\n\")\n",
    "        if inp=='y':\n",
    "            print(func_dict[api](param))\n",
    "            inp2 = input(\"Successfully Executed the query. Do you wish to continue(y/n)?\")\n",
    "            if inp2=='n':\n",
    "                state='stop'\n",
    "        else:\n",
    "            print(\"Cannot undertsand your input.Let's begin from the begining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f467d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from databricks_cli.sdk.api_client import ApiClient\n",
    "# from databricks_api import DatabricksAPI\n",
    "from databricks_cli.clusters.api import ClusterApi\n",
    "from databricks_cli.cluster_policies.api import ClusterPolicyApi\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_client = ApiClient(\n",
    "    host=\"https://lti-datascience-coe.cloud.databricks.com\",\n",
    "    token=\"dapi36506604639e5b76af065969be4fdcc9\"\n",
    "    )\n",
    "\n",
    "clusters_api = ClusterApi(api_client)\n",
    "cluster_policies_api = ClusterPolicyApi(api_client)\n",
    "#clusters_api.list_node_types()\n",
    "clusters_api.spark_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3ca118",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_clusters(\"0523-062338-165dk9wd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc9ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminate_clusters('0524-083742-jh2ln11w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8802364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_list('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65356df",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminate_clusters('0523-062338-165dk9wd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed52c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "permanent_delete_cluster_from_list(\"0524-083635-skj19rdw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\"0522-080639-6w9q2tvd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37705115",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.Parameters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15bdc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "len('NOPARAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a8bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks_api import DatabricksAPI\n",
    "# Provide a host and token\n",
    "db = DatabricksAPI(\n",
    "    host=\"https://lti-datascience-coe.cloud.databricks.com\",\n",
    "    token=\"dapi36506604639e5b76af065969be4fdcc9\"\n",
    ")\n",
    "\n",
    "db.cluster.create_cluster(\n",
    "    num_workers=25,\n",
    "    cluster_name=\"Demo-cluster1\",\n",
    "    spark_version=\"7.3.x-scala2.12\",\n",
    "    node_type_id=\"i3.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06653c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from databricks_api import DatabricksAPI\n",
    "# Provide a host and token\n",
    "db = DatabricksAPI(\n",
    "    host=\"https://lti-datascience-coe.cloud.databricks.com\",\n",
    "    token=\"dapi36506604639e5b76af065969be4fdcc9\"\n",
    ")\n",
    "\n",
    "def create_cluster(cluster_name, spark_version, node_type_id,num_workers):\n",
    "    try:\n",
    "        cluster = db.cluster.create_cluster(\n",
    "            cluster_name=cluster_name,\n",
    "            spark_version=spark_version,\n",
    "            node_type_id=node_type_id,\n",
    "            num_workers=num_workers\n",
    "        )\n",
    "        return cluster\n",
    "    except Exception as e:\n",
    "        print('Error creating Databricks cluster:', str(e))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66909ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_cluster(\"Demo-cluster1\",\"7.3.x-scala2.12\",\"i3.xlarge\",25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47f0bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_cluster('0524-104230-7r4feox1',20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d09c24f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cluster_id': '0524-104230-7r4feox1',\n",
       " 'creator_user_name': 'bhikari.swain@lntinfotech.com',\n",
       " 'driver': {'private_ip': '10.175.138.104',\n",
       "  'node_id': 'c4b62933d4f046eeb57c7e524c4b1c9b',\n",
       "  'instance_id': 'i-08c92b67417371d9f',\n",
       "  'start_timestamp': 1684925292650,\n",
       "  'node_aws_attributes': {'is_spot': False},\n",
       "  'node_attributes': {'is_spot': False},\n",
       "  'host_private_ip': '10.175.130.13'},\n",
       " 'executors': [{'private_ip': '10.175.134.18',\n",
       "   'node_id': '73c5c56b7b10487c80d86e2458be68e9',\n",
       "   'instance_id': 'i-010f61476f389838d',\n",
       "   'start_timestamp': 1684925293734,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.133.140'},\n",
       "  {'private_ip': '10.175.142.54',\n",
       "   'node_id': '79cc5c9e8d8a4c59b0067e88d1333b96',\n",
       "   'instance_id': 'i-0855838f6f0fb65ec',\n",
       "   'start_timestamp': 1684925293070,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.141.40'},\n",
       "  {'private_ip': '10.175.130.160',\n",
       "   'node_id': 'd1ca55f3f7734209aab8372e0ddf8eec',\n",
       "   'instance_id': 'i-03eb65f3ebb278967',\n",
       "   'start_timestamp': 1684925293382,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.137.126'},\n",
       "  {'private_ip': '10.175.132.250',\n",
       "   'node_id': '303e94598194434fb79da321dd16d0cb',\n",
       "   'instance_id': 'i-0a04ae0f173308985',\n",
       "   'start_timestamp': 1684925293017,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.129.62'},\n",
       "  {'private_ip': '10.175.141.176',\n",
       "   'node_id': 'fe2bed65791f47f0a4083193b3a2be42',\n",
       "   'instance_id': 'i-006b77d9f05528cb6',\n",
       "   'start_timestamp': 1684925293584,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.141.54'},\n",
       "  {'private_ip': '10.175.138.88',\n",
       "   'node_id': '9a536b9e23ab4a098059b3886443ac09',\n",
       "   'instance_id': 'i-022af9f20fd814dab',\n",
       "   'start_timestamp': 1684925293170,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.135.108'},\n",
       "  {'private_ip': '10.175.132.64',\n",
       "   'node_id': '1ebf6f579b5441eba0a1554fe26fe009',\n",
       "   'instance_id': 'i-072d63af187efe363',\n",
       "   'start_timestamp': 1684925293330,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.132.135'},\n",
       "  {'private_ip': '10.175.136.228',\n",
       "   'node_id': '66d32b0deeb141e399dc2a8bb1fd6e3a',\n",
       "   'instance_id': 'i-051ec41e6eb5a6e85',\n",
       "   'start_timestamp': 1684925292925,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.129.119'},\n",
       "  {'private_ip': '10.175.143.145',\n",
       "   'node_id': '2356d5c08f4e4fb59644f290cd730a10',\n",
       "   'instance_id': 'i-05ff76f38079613e4',\n",
       "   'start_timestamp': 1684925292742,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.131.93'},\n",
       "  {'private_ip': '10.175.130.230',\n",
       "   'node_id': '372b617c95f14fd58d8860be2b2a5367',\n",
       "   'instance_id': 'i-0b010823c3f507d60',\n",
       "   'start_timestamp': 1684925293821,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.141.216'},\n",
       "  {'private_ip': '10.175.140.176',\n",
       "   'node_id': '708cf4590e084b558bc05449bc564288',\n",
       "   'instance_id': 'i-055aa3a66a88b860b',\n",
       "   'start_timestamp': 1684925292973,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.140.204'},\n",
       "  {'private_ip': '10.175.130.36',\n",
       "   'node_id': 'a2d6ab004d0841e0a528a5682b7bdc61',\n",
       "   'instance_id': 'i-00007e35434dd1bd3',\n",
       "   'start_timestamp': 1684925293482,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.142.216'},\n",
       "  {'private_ip': '10.175.141.134',\n",
       "   'node_id': 'c8a37f2e3a6f49158b4e472c641d8254',\n",
       "   'instance_id': 'i-07be705f4337a623d',\n",
       "   'start_timestamp': 1684925292877,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.140.216'},\n",
       "  {'private_ip': '10.175.133.122',\n",
       "   'node_id': '4b3559b48aaf400e854d0c6c1ad0289b',\n",
       "   'instance_id': 'i-0a0184a57680e83bd',\n",
       "   'start_timestamp': 1684925292784,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.142.156'},\n",
       "  {'private_ip': '10.175.134.198',\n",
       "   'node_id': '1c9ef8e7756342d38cd52a560d2581f5',\n",
       "   'instance_id': 'i-0db3a963dfd58ea28',\n",
       "   'start_timestamp': 1684925293777,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.136.89'},\n",
       "  {'private_ip': '10.175.130.147',\n",
       "   'node_id': '4545cd3931444fbca6660ab619abce07',\n",
       "   'instance_id': 'i-0501ad084ca7a2f99',\n",
       "   'start_timestamp': 1684925292837,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.143.157'},\n",
       "  {'private_ip': '10.175.140.109',\n",
       "   'node_id': '26d29a3aab0f4b528a298be06fa094d7',\n",
       "   'instance_id': 'i-0b4ca47619ec8529b',\n",
       "   'start_timestamp': 1684925293277,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.131.78'},\n",
       "  {'private_ip': '10.175.132.49',\n",
       "   'node_id': '1ccac93bb5f64e36b87eb0e789521397',\n",
       "   'instance_id': 'i-046cc16fe2de3233a',\n",
       "   'start_timestamp': 1684925293224,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.128.8'},\n",
       "  {'private_ip': '10.175.136.33',\n",
       "   'node_id': 'da215b83bf424f129c99c67c362da542',\n",
       "   'instance_id': 'i-092fef3a96647d4cb',\n",
       "   'start_timestamp': 1684925293532,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.137.56'},\n",
       "  {'private_ip': '10.175.143.148',\n",
       "   'node_id': '205b3d58e70546eb9c604e0fa9745f05',\n",
       "   'instance_id': 'i-0dac3f71385cec8a2',\n",
       "   'start_timestamp': 1684925292697,\n",
       "   'node_aws_attributes': {'is_spot': False},\n",
       "   'node_attributes': {'is_spot': False},\n",
       "   'host_private_ip': '10.175.140.36'}],\n",
       " 'spark_context_id': 6746725807166987931,\n",
       " 'driver_healthy': True,\n",
       " 'jdbc_port': 10000,\n",
       " 'cluster_name': 'Demo-cluster',\n",
       " 'spark_version': '7.3.x-scala2.12',\n",
       " 'aws_attributes': {'first_on_demand': 0,\n",
       "  'availability': 'SPOT_WITH_FALLBACK',\n",
       "  'zone_id': 'us-east-1a',\n",
       "  'spot_bid_price_percent': 100},\n",
       " 'node_type_id': 'i3.xlarge',\n",
       " 'driver_node_type_id': 'i3.xlarge',\n",
       " 'autotermination_minutes': 0,\n",
       " 'enable_elastic_disk': False,\n",
       " 'disk_spec': {},\n",
       " 'cluster_source': 'API',\n",
       " 'enable_local_disk_encryption': False,\n",
       " 'instance_source': {'node_type_id': 'i3.xlarge'},\n",
       " 'driver_instance_source': {'node_type_id': 'i3.xlarge'},\n",
       " 'effective_spark_version': '7.3.x-scala2.12',\n",
       " 'state': 'RESIZING',\n",
       " 'state_message': 'Finding instances for new nodes, acquiring more instances if necessary',\n",
       " 'start_time': 1684924950816,\n",
       " 'last_state_loss_time': 0,\n",
       " 'last_activity_time': 1684925325287,\n",
       " 'last_restarted_time': 1684925362189,\n",
       " 'num_workers': 25,\n",
       " 'default_tags': {'Vendor': 'Databricks',\n",
       "  'Creator': 'bhikari.swain@lntinfotech.com',\n",
       "  'ClusterName': 'Demo-cluster',\n",
       "  'ClusterId': '0524-104230-7r4feox1'},\n",
       " 'init_scripts_safe_mode': False}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from databricks_api import DatabricksAPI\n",
    "# Provide a host and token\n",
    "db = DatabricksAPI(\n",
    "    host=\"https://lti-datascience-coe.cloud.databricks.com\",\n",
    "    token=\"dapi36506604639e5b76af065969be4fdcc9\"\n",
    ")\n",
    "\n",
    "db.cluster.get_cluster(\n",
    "    '0524-104230-7r4feox1',\n",
    "    headers=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0b71648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks_api import DatabricksAPI\n",
    "# Provide a host and token\n",
    "db = DatabricksAPI(\n",
    "    host=\"https://lti-datascience-coe.cloud.databricks.com\",\n",
    "    token=\"dapi36506604639e5b76af065969be4fdcc9\"\n",
    ")\n",
    "\n",
    "def create_cluster_policy(policy_name,definition):\n",
    "    try:\n",
    "        policy = db.policy.create_policy(\n",
    "                 policy_name = 'Test_Policy' ,\n",
    "                 definition = definition\n",
    "                 )\n",
    "        return policy\n",
    "    except Exception as e:\n",
    "        print('Error creating Databricks cluster:', str(e))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f157c608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'policy_id': '9C63D8C50400CE0A'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        db.policy.create_policy(\n",
    "                 name = 'Test_Policy' ,\n",
    "                 definition = \"{ \\\"custom_tags.test_tag\\\": { \\\"type\\\": \\\"fixed\\\", \\\"value\\\": \\\"test_value\\\" } }\\n\",\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b794b7cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9C63D8C50400CE0A</td>\n",
       "      <td>Test_Policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9C63D8C50400CE14</td>\n",
       "      <td>Test_Policy_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9C63D8C50400CE3A</td>\n",
       "      <td>Test_policy_Charan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9C63D8C50400C2F2</td>\n",
       "      <td>work_compute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9C6308F703001BE4</td>\n",
       "      <td>Personal Compute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9C6308F703001BE5</td>\n",
       "      <td>Power User Compute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9C6308F703001BE6</td>\n",
       "      <td>Shared Compute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9C6308F703001BE7</td>\n",
       "      <td>Job Compute</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          policy_id                name\n",
       "0  9C63D8C50400CE0A         Test_Policy\n",
       "1  9C63D8C50400CE14       Test_Policy_1\n",
       "2  9C63D8C50400CE3A  Test_policy_Charan\n",
       "3  9C63D8C50400C2F2        work_compute\n",
       "4  9C6308F703001BE4    Personal Compute\n",
       "5  9C6308F703001BE5  Power User Compute\n",
       "6  9C6308F703001BE6      Shared Compute\n",
       "7  9C6308F703001BE7         Job Compute"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_policy_list('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07299b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\10689805'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "82ba2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_policy(policy_name, config_file_path):\n",
    "    api_endpoint = \"https://lti-datascience-coe.cloud.databricks.com/api/2.0/policies/clusters/create\"  # Replace <databricks-instance> with your Databricks instance URL\n",
    "    api_token = \"dapi36506604639e5b76af065969be4fdcc9\"\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer \" + api_token,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    with open(config_file_path, 'r') as file:\n",
    "        config_data = json.load(file)\n",
    "\n",
    "    config_data[\"name\"] = policy_name\n",
    "\n",
    "    response = requests.post(api_endpoint, headers=headers, json=config_data)\n",
    "    response_json = response.json()\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(\"Cluster policy created successfully with ID:\", response_json[\"policy_id\"])\n",
    "    else:\n",
    "        print(\"Error creating cluster policy:\", response_json[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0c8b427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster policy created successfully with ID: 9C63D8C50400CE14\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "create_cluster_policy(\"Test_Policy_1\",\"config_file_path.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "523b1d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\10689805'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5dd6eff2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_policy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m         \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTest_Policy_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdefinition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig_file_path.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m         \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\databricks_cli\\sdk\\service.py:849\u001b[0m, in \u001b[0;36mPolicyService.create_policy\u001b[1;34m(self, policy_name, definition, headers, name)\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    848\u001b[0m     _data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m--> 849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/policies/clusters/create\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\databricks_cli\\sdk\\api_client.py:159\u001b[0m, in \u001b[0;36mApiClient.perform_query\u001b[1;34m(self, method, path, data, headers, files, version)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;66;03m# Multipart file upload\u001b[39;00m\n\u001b[0;32m    163\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mrequest(method, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_url(path, version\u001b[38;5;241m=\u001b[39mversion), files \u001b[38;5;241m=\u001b[39m files, data \u001b[38;5;241m=\u001b[39m data,\n\u001b[0;32m    164\u001b[0m                                     verify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify, headers \u001b[38;5;241m=\u001b[39m headers)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\requests\\adapters.py:487\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    484\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 487\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n\u001b[0;32m   1045\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1046\u001b[0m         (\n\u001b[0;32m   1047\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnverified HTTPS request is being made to host \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1052\u001b[0m         InsecureRequestWarning,\n\u001b[0;32m   1053\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\urllib3\\connection.py:419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_certs\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_cert_dir\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(context, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_default_certs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    416\u001b[0m ):\n\u001b[0;32m    417\u001b[0m     context\u001b[38;5;241m.\u001b[39mload_default_certs()\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;66;03m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# for the host.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    436\u001b[0m     default_ssl_context\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock\u001b[38;5;241m.\u001b[39mversion() \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTLSv1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTLSv1.1\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    440\u001b[0m ):\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py:449\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    437\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    438\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn HTTPS request has been made, but the SNI (Server Name \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndication) extension to TLS is not available on this platform. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m         SNIMissingWarning,\n\u001b[0;32m    446\u001b[0m     )\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m send_sni:\n\u001b[1;32m--> 449\u001b[0m     ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    453\u001b[0m     ssl_sock \u001b[38;5;241m=\u001b[39m _ssl_wrap_socket_impl(sock, context, tls_in_tls)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py:493\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m server_hostname:\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(sock)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ssl.py:512\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    507\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    508\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    509\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ssl.py:1070\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m   1068\u001b[0m             \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1070\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\ssl.py:1341\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[0;32m   1340\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1341\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1342\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "        db.policy.create_policy(\n",
    "                 name = 'Test_Policy_1' ,\n",
    "                 definition = \"config_file_path.json\",\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0439f681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'autoscale.max_workers': {'type': 'range', 'maxValue': '25', 'defaultValue': 5}}\n"
     ]
    }
   ],
   "source": [
    "   with open(\"config_file_path.json\", 'r') as file:\n",
    "        config_data = json.load(file)\n",
    "        print(config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d259636d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'policy_id': '9C63D8C50400CE0A',\n",
       " 'name': 'Test_Policy',\n",
       " 'definition': '{ \"custom_tags.test_tag\": { \"type\": \"fixed\", \"value\": \"test_value\" } }\\n',\n",
       " 'created_at_timestamp': 1684933691000,\n",
       " 'is_default': False}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.policy.get_policy(\n",
    "    policy_id = \"9C63D8C50400CE0A\",\n",
    "    headers=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "53964962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files': [{'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/1635837431815.pdf',\n",
       "   'is_dir': False,\n",
       "   'file_size': 983627,\n",
       "   'modification_time': 1651727783000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/CollatedPRCBenchmarks_080721_Debt_TransformedFormat-1.csv',\n",
       "   'is_dir': False,\n",
       "   'file_size': 6594,\n",
       "   'modification_time': 1650952227000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/CollatedPRCBenchmarks_080721_Debt_TransformedFormat-2.csv',\n",
       "   'is_dir': False,\n",
       "   'file_size': 6594,\n",
       "   'modification_time': 1650953091000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/CollatedPRCBenchmarks_080721_Debt_TransformedFormat-3.csv',\n",
       "   'is_dir': False,\n",
       "   'file_size': 6594,\n",
       "   'modification_time': 1650953199000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/CollatedPRCBenchmarks_080721_Debt_TransformedFormat.csv',\n",
       "   'is_dir': False,\n",
       "   'file_size': 6594,\n",
       "   'modification_time': 1650951816000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/CollatedPRCBenchmarks_080721_Debt_TransformedFormat.xlsx',\n",
       "   'is_dir': False,\n",
       "   'file_size': 22601,\n",
       "   'modification_time': 1650275264000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/CollatedPRCBenchmarks_080721_Debt_TransformedFormat__1_.xlsx',\n",
       "   'is_dir': False,\n",
       "   'file_size': 22601,\n",
       "   'modification_time': 1650828088000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/Databricksapi_Description.csv',\n",
       "   'is_dir': False,\n",
       "   'file_size': 713,\n",
       "   'modification_time': 1683710714000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/Input',\n",
       "   'is_dir': True,\n",
       "   'file_size': 0,\n",
       "   'modification_time': 0},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/ListofTier1Benchmarks_All_category.csv',\n",
       "   'is_dir': False,\n",
       "   'file_size': 6857,\n",
       "   'modification_time': 1650952476000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/ListofTier1Benchmarks_All_category.xlsx',\n",
       "   'is_dir': False,\n",
       "   'file_size': 23363,\n",
       "   'modification_time': 1650274753000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/ListofTier1Benchmarks_All_category__1_.xlsx',\n",
       "   'is_dir': False,\n",
       "   'file_size': 23363,\n",
       "   'modification_time': 1650828007000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/Results',\n",
       "   'is_dir': True,\n",
       "   'file_size': 0,\n",
       "   'modification_time': 0},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/Results1529316031771Alerts.csv',\n",
       "   'is_dir': False,\n",
       "   'file_size': 560,\n",
       "   'modification_time': 1652076306000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/Results1529316031771Data_Points.csv',\n",
       "   'is_dir': False,\n",
       "   'file_size': 1972,\n",
       "   'modification_time': 1652076306000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/ResultsTata_Young_Citizens_Fund_covered_callAlerts.csv',\n",
       "   'is_dir': False,\n",
       "   'file_size': 752,\n",
       "   'modification_time': 1652076323000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/ResultsTata_Young_Citizens_Fund_covered_callData_Points.csv',\n",
       "   'is_dir': False,\n",
       "   'file_size': 411,\n",
       "   'modification_time': 1652076323000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/assetAllocationPattern.csv',\n",
       "   'is_dir': False,\n",
       "   'file_size': 3606,\n",
       "   'modification_time': 1651637394000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/corporateDebtPattern.csv',\n",
       "   'is_dir': False,\n",
       "   'file_size': 1769,\n",
       "   'modification_time': 1650274513000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/model',\n",
       "   'is_dir': True,\n",
       "   'file_size': 0,\n",
       "   'modification_time': 0},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/model-best',\n",
       "   'is_dir': True,\n",
       "   'file_size': 0,\n",
       "   'modification_time': 0},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/model_best-1.zip',\n",
       "   'is_dir': False,\n",
       "   'file_size': 4287080,\n",
       "   'modification_time': 1651638861000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/model_best-2.zip',\n",
       "   'is_dir': False,\n",
       "   'file_size': 4287080,\n",
       "   'modification_time': 1651638999000},\n",
       "  {'path': '/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/model_best.zip',\n",
       "   'is_dir': False,\n",
       "   'file_size': 4287080,\n",
       "   'modification_time': 1651468683000}]}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = DatabricksAPI(\n",
    "    host=\"https://lti-datascience-coe.cloud.databricks.com\",\n",
    "    token=\"dapi36506604639e5b76af065969be4fdcc9\"\n",
    ")\n",
    "db.dbfs.list(\n",
    "    path=\"/FileStore/shared_uploads/bhikari.swain@lntinfotech.com/\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
